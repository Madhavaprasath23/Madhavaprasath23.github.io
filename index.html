<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <link href='https://fonts.googleapis.com/css?family=Roboto' rel='stylesheet'>
    <link href="style.css" rel="stylesheet">
    <title>Maddy's Portfolio</title>
  </head>
  <body style="font-family: Roboto;">
    <nav class="navbar sticky-top navbar-expand-lg navbar-dark bg-dark">
      <div class="container-fluid">
        <span class="navbar-brand" href="#">Madhava Prasath</span>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse justify-content-end" id="navbarNav">
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/Madhavaprasath23/" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="" class="bi bi-github" viewBox="0 0 16 16">
              <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.01 8.01 0 0 0 16 8c0-4.42-3.58-8-8-8"/>
            </svg></a>
          </li>
          <ul class="navbar-nav">
            <li class="nav-item">
              <a class="nav-link About-Me active" aria-current="page" href="#About-Me">About Me</a>
            </li>
            <li class="nav-item">
              <a class="nav-link Publications" href="#Publications">Publications</a>
            </li>
            <li class="nav-item">
              <a class="nav-link Research" href="#Research">Research Interest</a>
            </li>
            <li class="nav-item">
              <a class="nav-link Skills" href="#Skills">Skills</a>
            </li><li class="nav-item">
              <a class="nav-link Lecturenotes" href="#Lecturenotes">Lecture Notes</a>
            </li>
            </li><li class="nav-item">
              <a class="nav-link Contact" href="#Contact">Contact</a>
            </li>
          </ul>
          
        </div>
      </div>
    </nav>
    
        <section id="About-Me" style="height: auto;">
        <div class="container" style="padding-top: 5rem;"  id="About Me">
            <div class="clearfix">
                <img src="Assets/My Image.jpg"  style="height: 20%; width: 20%;"class="col-md-6 float-md-end mb-3 ms-md-3 rounded-circle">
                
                <h1 style="font-size: 2.5rem; font-weight: bolder;">
                    Hey all This is Madhava Prasath!
                </h1>
                    <p style="font-size: large; text-align: justify;">
                        I dont have much notoriety, I am a Btech final year student at R.M.D. Engineering College, Kavaraipettai TamilNadu. My interest are Deeplearning, applications of deeplearning such as in Medicine and Convex Optimization. I love Deeplearning and Maths behind it. In the section Research Interest I would have specified about my interest in much more convinent fashion. 
                        I am now looking towards contributing to this field by doing useful research and targetting good conferences and journals with that I can improve my profile and  also have a good knowledge about this field,  In my leisure time I make games using Godot Game Engine unfortunately the git account I used to commit is lost because of 2FA so you can just see my previous games if you are interested. Also I have attached my CV below you can find about my previous Internships and certifications I have worked on.
                    </p>
                    <p style="font-size: large; text-align: justify;">
                      Mentor: <a href="https://prajdabre.github.io/" target="_blank" rel="noopener noreferrer">Prof Raj Dabre</a> ( Researcher @ <a href="https://astrec.nict.go.jp/en/" target="_blank" rel="noopener noreferrer">NICT, Japan</a>, Adjunct Faculty @ <a href="https://ai4bharat.iitm.ac.in/" target="_blank" rel="noopener noreferrer"> IIT Madras (AI4Bharat)</a>, Honorary Visiting Assistant Professor @ <a href="https://www.cfilt.iitb.ac.in/" target="_blank" rel="noopener noreferrer">IIT Bombay (CFILT)</a>)
                      I am extremely Gratefull for him and his guidance (and am also gratefull that he considers me as a human )
                  </p>
                    <p style="font-size: large; text-align: justify;">
                        Hobbies: Listening to Music, Playing games, Walking till I ease my mind off 
                    </p>
                    <p style="font-size: large;">
                        Below you can find my C.V. 
                    </p>
                    <button type="button" class="btn btn-dark">
                        
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-download" viewBox="0 0 16 16" style="color: white;">
                          <path d="M.5 9.9a.5.5 0 0 1 .5.5v2.5a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-2.5a.5.5 0 0 1 1 0v2.5a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2v-2.5a.5.5 0 0 1 .5-.5"/>
                          <path d="M7.646 11.854a.5.5 0 0 0 .708 0l3-3a.5.5 0 0 0-.708-.708L8.5 10.293V1.5a.5.5 0 0 0-1 0v8.793L5.354 8.146a.5.5 0 1 0-.708.708z"/>
                        </svg>

                          <a href="Assets/Madhava_prasath_CV_09_10_2024.pdf" download="Madhavaprasath_CV.pdf" style="text-decoration: none; color: white;">Download CV</a>
                      </button>
                    <br>
                      <div class="clear-fix">
                        <p class="heading" style="padding-top: 1rem;">
                          Papers That are my favorite (In no particular order)
                        </p>
                        <ul class="paper_list">
                          <li>
                            <b>Attention Is All You Need</b> - You know it I know it hands down transformed Deep Learning in all fields which are dominated in the era of traditional sequence models such as RNNs ,LSTM and ConvNets, indeed Attention is all we needed all though it is great it still suffers from quadratic time complexity when the model is used in inference and as well as training, To tackle this lot methods are proposed such as efficient attention (training), KV cacheing (inference), still its the greatest. 
                            [
                            <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer">arXiv</a>
                            ]

                          </li>
                          <br>
                          <li>
                            <b>Image is worth 16 x 16 words</b> - Another classic which is a direct application of the Encoder stack from transformers on Understanding task (aka BERT) but this paved the way for ViT, By tokenzing an image by using Non Overlapping Convoluiton layers and adding with learnable position encoding (similar to GPT2), This has significantly created a new wave of Vision Transformers (ViTs) such as DETER (Encoder decoder architecture) and Many more it is primarily pretrained on JFT-300M (internal dataset by google) thats how it shows more capable understanding.
                            [
                            <a href="https://arxiv.org/abs/2010.11929" target="_blank" rel="noopener noreferrer">arXiv</a>
                            ]
                          </li>
                          <br>
                          <li >
                            <b>CLIP</b> - This paper shows that even for Understanding Single Modal tasks such as for classification, We could use Multimodal datas to further more enhance the understanding of the data thus increasing the performance on the Single modal tasks, just like how we learn about objects. Improvements from the loss function of CLIP leads us to SIGLIP
                            [
                            <a href="https://arxiv.org/abs/2103.00020" target="_blank" rel="noopener noreferrer">arXiv</a>
                            ]
                          </li>
                          <br>
                          <li>
                            <b>Flamingo</b> - This paper shows Aliging the Vision encoder and text LLMs by using series of Gated Cross attention layer , The LLM is frozen and vision encoder (In the paper they have used conformer) effectively aligning vison and text modality although methodology like Llava exists (In which image representations are directly sent into decoder only transformer with the use of Vision Encoder(Linear on top of frozen ViT - v1, MLP on top of frozen ViT - v2)) it is a bit of personal favorite for me 
                            [
                            <a href="https://arxiv.org/abs/2204.14198" target="_blank" rel="noopener noreferrer">arXiv</a>
                            ]
                          </li>
                          <br>
                          <li>
                            <b>VQ-VAE</b> - This paper converts the continous nature of latent space in VAE to discrete nature by using embedding layers, The each vector value is  mapped to closest embedding layer value (tokenizing it), In this paper they also use distance based restriction on latents. In my opinon VQ-VAE have paved the way for Latent based diffusion models for eg Video poet uses a Multimodal LLM which predicts the token of image or video just like in text. The tokens are encoded and decoded using MAG-VIT v2 which is a VQ-VAE
                            [
                            <a href="https://arxiv.org/abs/1711.00937" target="_blank" rel="noopener noreferrer">arXiv</a>
                            ]
                          </li>
                          <br>
                          <li>
                            <b>Mamba</b> -  This paper shows the long term nature of SSMs and how it could be incredibly usefull, For me Mamba isn't a one day thing the foundation of Mamba models are laid from S4 SSMs , S4 highlighted that transformers perform worst on Long range tasks on one such task PATH - X transformers performed significantly worse than random guessing (less than 50%) S4 address the issue by initalizing the parameters of it from HiPPO Matrix (again from the same authors of Mamba) to make it long range depended, S4D initalizes the matrix Diagonally, S5 improves the discretiztion from S4 by incorpating ZOH (zero order hold) 
                            , S6 (mamba) combines the gated networks (RNN and LSTM) and H3 (hungry hungry Hippos, the Hippo matrix I mentioned before) and ZOH from S5. further more improvements are done on parallelizing the parameter which led to 1SS-Matrix now the SSMs are equalent to Transformers
                            [
                            <a href="https://arxiv.org/abs/2312.00752" target="_blank" rel="noopener noreferrer">arXiv v1</a>,
                            <a href="https://arxiv.org/abs/2405.21060" target="_blank" rel="noopener noreferrer">arXiv v2</a>
                            ]
                          
                          </li>
                          <br>
                          <li>
                            <b>Am not doing justice by just mentioning only these papers I will make a seperate page dedicated to this later</b>
                          </li>
                        </ul>

                      </div>
                    </div>
        </div>
        </section>

        <section id="Publications" style="height: auto;">
            <div class="container" style="padding-top: 5rem;">
                <div class="clearfix">
                  <p class="heading">
                    Publications
                    </p>
                    <p class="headingcap"> I just started my journey on publication I have listed one paper for now will update regularly when ever I publish a paper</p>
                    <ul class="paper_list">
                        <li>A Comprehensive Survey of Mamba Architectures for
                            Medical Image Analysis: Classification, Segmentation,
                            Restoration and Beyond 
                              [
                              <a href="https://arxiv.org/abs/2410.02362" target="_blank" rel="noopener noreferrer">arXiv</a>,
                              <a href="https://github.com/Madhavaprasath23/Awesome-Mamba-Papers-On-Medical-Domain" target="_blank" rel="noopener noreferrer">Github</a>
                              ]
                            
                        </li>

                      </ul>
                </div>
        </section>

        <section id="Research" style="height: auto;">
            <div class="container" style="padding-top: 5rem;">
              <p class="heading">
                Research Interest
                </p>
              <p class="headingcap">
                I can collaborate easily in these areas, comprehend concepts numerically, attempt to explain them theoretically, and try to add something new. I'm confident that I can add something new to these areas.
              </p>
              <ul class="paper_list">
                <li>Deep Learning</li>
                <li>Deep Learning for Medicine</li>
                <li>Semi supervised Learning</li>
                <li>Distributed training </li>
                <li>Statistics and Probability</li>
                <li>LLMs & Multimodal LLMs</li>
                <li>Machine Translation</li>
                <li>Language Modeling</li>
                <li>AI Agents</li>
              </ul>
            </div>
        </section>


    <section id="Skills" style="height: auto;">
      <div class="container" style="padding-top: 5rem;">
        <p class="heading">
          Skills
        </p>
        <p class="headingcap">
          These represent my current skill level for the previously specified research interest.
        </p>
        <ul class="paper_list">
          <li>Deep Learning</li>
          <li>Reinforcment Learning</li>
          <li>Self Supervised Learning</li>
          <li>Semi supervised Learning</li>
          <li>Distributed training </li>
          <li>Statistics and Probability</li>
          <li>Game programming</li>
          <li>Convex Optimization</li>
        </ul>
      </div>
    </section>
    <section id="Lecturenotes" style="height: auto;">
      <div class="container"  style="padding-top: 5rem;">
        <p class="heading"> 
          Lecture Notes
        </p>
        <p class="headingcap">
          I usally present/conduct paper reading sessions on Ai4bharat Discord server (Every Friday - 6:00 pm - 7:00 pm IST/ 12:30 pm - 1:30 pm UTC) the list of the lectures are given below, You can also join AI4bharat discord server <a href="https://discord.com/invite/68x8rZC9wD" target="_blank" rel="noopener noreferrer">here</a>
        </p>
        <ul class="paper_list">
          <li>REFT
                [
                  <a href="https://drive.google.com/drive/folders/1AnA8Zd3Nj812z31goR3FeXckVwGK0mCt?usp=drive_link" target="_blank" rel="noopener noreferrer">Slides</a>,
                  <a href="https://youtu.be/d024AM6QBsc?si=7DVUKXWkDUjmCT6X" target="_blank" rel="noopener noreferrer">Video</a>
                ]
          </li>
          <li>Transformers to SSMs (Recurrent part)
                [
                 <a href="https://drive.google.com/drive/folders/1zol1dz42i8cxFzG_ixETKCywgkhbQ_w5?usp=drive_link" target="_blank" rel="noopener noreferrer">Slides</a>,
                <a href="https://youtu.be/oberMf6WSsQ?si=zUJx9SAHg0TW29sr" target="_blank" rel="noopener noreferrer">Video 1</a>,
                <a href="https://youtu.be/PapnKy3xqcA?si=QpuaLBDOpydsTGKZ" target="_blank" rel="noopener noreferrer">Video 2</a>
                ]
          </li>
          <li>Multitoken Prediction (Hands on)
                [
                  <a href="https://drive.google.com/drive/folders/1MEX2DAauEWpwVLA7crwHLFOV_hzqWfn4?usp=drive_link" target="_blank" rel="noopener noreferrer">Slides</a>,
                  <a href="https://youtu.be/CtOn11wUi1o?si=jLnX7mtGj9JiRUfU" target="_blank" rel="noopener noreferrer">Video</a> 
                ]
          </li>


          <li>Llama3.1 - Heard of Models 
                [
                  <a href="https://drive.google.com/drive/folders/1MEX2DAauEWpwVLA7crwHLFOV_hzqWfn4?usp=drive_link" target="_blank" rel="noopener noreferrer">Slides</a>
                ]
          </li>

          <li>VQ-VAE to Multimodal LLMs 
              [
                <a href="https://drive.google.com/drive/folders/1pL2XBYBQMgtnnSH_vKvfoYt6w3c9ZQnO?usp=drive_link" target="_blank" rel="noopener noreferrer">Slides</a>
              ]
        </li>
        <li>KV Cache (Hands On)
          [
           <a href="https://drive.google.com/drive/folders/17tzZXfUciajObiVHuh6OtcH8T3HqoQXE?usp=sharing" target="_blank" rel="noopener noreferrer">Slides</a> ,
           <a href="https://github.com/Madhavaprasath23/Nano_GPT-Inference" target="_blank" rel="noopener noreferrer">Github</a>
           ]
    </li>
        </ul>
      </div>
    </section>
    <section id="Contact" style="height: auto;">
      <div class="container"  style="padding-top: 5rem;">
        <p class="heading">
          Contact Me
        </p>
        <p class="headingcap">
          If you are interested in my profile you can contact me on following platforms 
        </p>
        <ul class="Socials">
          <li> <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" class="bi bi-linkedin" viewBox="0 0 16 16">
            <path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"/>
          </svg> - <a href="https://www.linkedin.com/in/madhava-prasath-1b6278229/" target="_blank" rel="noopener noreferrer">Madhava prasath</a></li>
          <li><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" class="bi bi-twitter-x" viewBox="0 0 16 16">
            <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865z"/>
          </svg> - <a href="https://x.com/madddyawesome" target="_blank" rel="noopener noreferrer">@maddyawesome</a></li>
          <li><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" class="bi bi-discord" viewBox="0 0 16 16">
            <path d="M13.545 2.907a13.2 13.2 0 0 0-3.257-1.011.05.05 0 0 0-.052.025c-.141.25-.297.577-.406.833a12.2 12.2 0 0 0-3.658 0 8 8 0 0 0-.412-.833.05.05 0 0 0-.052-.025c-1.125.194-2.22.534-3.257 1.011a.04.04 0 0 0-.021.018C.356 6.024-.213 9.047.066 12.032q.003.022.021.037a13.3 13.3 0 0 0 3.995 2.02.05.05 0 0 0 .056-.019q.463-.63.818-1.329a.05.05 0 0 0-.01-.059l-.018-.011a9 9 0 0 1-1.248-.595.05.05 0 0 1-.02-.066l.015-.019q.127-.095.248-.195a.05.05 0 0 1 .051-.007c2.619 1.196 5.454 1.196 8.041 0a.05.05 0 0 1 .053.007q.121.1.248.195a.05.05 0 0 1-.004.085 8 8 0 0 1-1.249.594.05.05 0 0 0-.03.03.05.05 0 0 0 .003.041c.24.465.515.909.817 1.329a.05.05 0 0 0 .056.019 13.2 13.2 0 0 0 4.001-2.02.05.05 0 0 0 .021-.037c.334-3.451-.559-6.449-2.366-9.106a.03.03 0 0 0-.02-.019m-8.198 7.307c-.789 0-1.438-.724-1.438-1.612s.637-1.613 1.438-1.613c.807 0 1.45.73 1.438 1.613 0 .888-.637 1.612-1.438 1.612m5.316 0c-.788 0-1.438-.724-1.438-1.612s.637-1.613 1.438-1.613c.807 0 1.451.73 1.438 1.613 0 .888-.631 1.612-1.438 1.612"/>
          </svg> - <a >madhavaprasath</a></li>
          <li><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" class="bi bi-envelope-at" viewBox="0 0 16 16">
            <path d="M2 2a2 2 0 0 0-2 2v8.01A2 2 0 0 0 2 14h5.5a.5.5 0 0 0 0-1H2a1 1 0 0 1-.966-.741l5.64-3.471L8 9.583l7-4.2V8.5a.5.5 0 0 0 1 0V4a2 2 0 0 0-2-2zm3.708 6.208L1 11.105V5.383zM1 4.217V4a1 1 0 0 1 1-1h12a1 1 0 0 1 1 1v.217l-7 4.2z"/>
            <path d="M14.247 14.269c1.01 0 1.587-.857 1.587-2.025v-.21C15.834 10.43 14.64 9 12.52 9h-.035C10.42 9 9 10.36 9 12.432v.214C9 14.82 10.438 16 12.358 16h.044c.594 0 1.018-.074 1.237-.175v-.73c-.245.11-.673.18-1.18.18h-.044c-1.334 0-2.571-.788-2.571-2.655v-.157c0-1.657 1.058-2.724 2.64-2.724h.04c1.535 0 2.484 1.05 2.484 2.326v.118c0 .975-.324 1.39-.639 1.39-.232 0-.41-.148-.41-.42v-2.19h-.906v.569h-.03c-.084-.298-.368-.63-.954-.63-.778 0-1.259.555-1.259 1.4v.528c0 .892.49 1.434 1.26 1.434.471 0 .896-.227 1.014-.643h.043c.118.42.617.648 1.12.648m-2.453-1.588v-.227c0-.546.227-.791.573-.791.297 0 .572.192.572.708v.367c0 .573-.253.744-.564.744-.354 0-.581-.215-.581-.8Z"/>
          </svg> - <a> 21204028@rmd.ac.in , madhavprasath088@gmail.com</a></li>
        </ul>
        </div>
    </section>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
    <script src="script.js"></script>

  </body>
</html>

